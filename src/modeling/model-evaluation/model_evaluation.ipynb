{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0f65f00ed884b0d74a6878126da3c63663535319d87509092f4fd534b10c59dc8",
   "display_name": "Python 3.8.8 64-bit ('asteroid_thesis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Evaluation \n",
    "This is the script to generate visuals and images of model results, since many of the models did not successfully train on validation sets.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.distribute import MirroredStrategy, HierarchicalCopyAllReduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.config.run_functions_eagerly(False)\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "strategy = MirroredStrategy(cross_device_ops=HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation generator\n",
    "from model_utils import artificial_lunar_landscapes, generate_image_paths\n",
    "from model_utils_sobel import artificial_lunar_landscapes as artificial_lunar_landscapes_sobel\n",
    "from model_utils_sobel import  generate_image_paths as generate_image_paths_sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "batch_size = 2\n",
    "image_size = (480,720,1)\n",
    "input_processed_size = (480,720,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ninput_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\\n)\\ntrain_generator = artificial_lunar_landscapes(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths\\n)\\n\\n\\n#test generator\\ninput_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\\n)\\ntest_generator = artificial_lunar_landscapes(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths\\n)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# ORIGNIAL TRAIN TEST GENERATOR (no Sobel)\n",
    "#training generator\n",
    "\"\"\"\n",
    "input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    ")\n",
    "train_generator = artificial_lunar_landscapes(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths\n",
    ")\n",
    "\n",
    "\n",
    "#test generator\n",
    "input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    ")\n",
    "test_generator = artificial_lunar_landscapes(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ninput_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\\n    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\\n)\\ntrain_generator_sobel = artificial_lunar_landscapes_sobel(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    image_processed_size = input_processed_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths,\\n    input_img_processed_paths=process_img_paths\\n)\\n\\n#test generator with sobel - X output is [original_image, processed_image]\\ninput_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\\n    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\\n)\\ntest_generator_sobel = artificial_lunar_landscapes_sobel(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    image_processed_size = input_processed_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths,\\n    input_img_processed_paths=process_img_paths\\n)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "### SOBEL GENERATOR\n",
    "# training generator with sobel - X output is [original_image, processed_image]\n",
    "\"\"\"\n",
    "input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    ")\n",
    "train_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    image_processed_size = input_processed_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths,\n",
    "    input_img_processed_paths=process_img_paths\n",
    ")\n",
    "\n",
    "#test generator with sobel - X output is [original_image, processed_image]\n",
    "input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    ")\n",
    "test_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    image_processed_size = input_processed_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths,\n",
    "    input_img_processed_paths=process_img_paths\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "def weighted_bincrossentropy(true, pred, weight_zero = 0.1, weight_one = 1):\n",
    "    \"\"\"\n",
    "    Calculates weighted binary cross entropy. The weights are fixed.\n",
    "        \n",
    "    This can be useful for unbalanced catagories.\n",
    "    \n",
    "    Adjust the weights here depending on what is required.\n",
    "    \n",
    "    For example if there are 10x as many positive classes as negative classes,\n",
    "        if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives # predict rock but actually no rock\n",
    "        will be penalize 10 times as much as false negatives. # predict no rock but actually rock\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the binary cross entropy\n",
    "    bin_crossentropy = keras.backend.binary_crossentropy(true, pred)\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "\n",
    "    return keras.backend.mean(weighted_bin_crossentropy)\n",
    "\n",
    "def wbce( y_true, y_pred, weight1=1, weight0=0.1 ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight1 + (1 - y_true) * K.log(1 - y_pred) * weight0 )\n",
    "    return K.mean( logloss, axis=-1)"
   ]
  },
  {
   "source": [
    "### Functions\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model-0.h5',\n",
       " 'model-1.h5',\n",
       " 'model-2.h5',\n",
       " 'model-3.h5',\n",
       " 'model-4.h5',\n",
       " 'model-5.h5',\n",
       " 'model-6.h5',\n",
       " 'model-7.h5',\n",
       " 'model-8.h5',\n",
       " 'model-9.h5',\n",
       " 'model-10.h5',\n",
       " 'model-11.h5',\n",
       " 'model-12.h5',\n",
       " 'model-13.h5',\n",
       " 'model-14.h5',\n",
       " 'model-15.h5',\n",
       " 'model-16.h5',\n",
       " 'model-17.h5',\n",
       " 'model-18.h5',\n",
       " 'model-19.h5']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model_checkpoint_directory = '../results/simple-modeling/unet-weighted-bce-trainval/checkpoints/'\n",
    "os.listdir(model_checkpoint_directory)\n",
    "\n",
    "model_list = []\n",
    "for i in range(0,20):\n",
    "    model_list.append(f'model-{i}.h5')\n",
    "\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(model_directory=None, custom_objects=None):\n",
    "    \"\"\" LOAD GENERATOR\"\"\"\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    "    )\n",
    "    train_generator = artificial_lunar_landscapes(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths\n",
    "    )\n",
    "\n",
    "\n",
    "    #test generator\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    "    )\n",
    "    test_generator = artificial_lunar_landscapes(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths\n",
    "    )\n",
    "\n",
    "\n",
    "    \"\"\" END GENERATOR \"\"\"\n",
    "    \n",
    "    \n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    print(model.summary())\n",
    "    \n",
    "    #with strategy.scope():\n",
    "    print(\"Evaluating on Training Set\")\n",
    "    results_train = model.evaluate(train_generator)\n",
    "    \n",
    "    print(\"Evaluating on Test Set\")\n",
    "    results_val = model.evaluate(test_generator)\n",
    "    \n",
    "    del test_generator\n",
    "    del train_generator\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    \n",
    "    \n",
    "    return results_train, results_val\n",
    "\n",
    "def model_func_branches_training_eval(model_directory, custom_objects):\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    "    )\n",
    "    train_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "    print(\"Evaluating on Training Set\")\n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    print(model.summary())\n",
    "    results_train = model.evaluate(train_generator_sobel)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    return results_train\n",
    "\n",
    "def model_func_branches_testing_eval(model_directory, custom_objects):\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    "    )\n",
    "    test_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    results_val = model.evaluate(test_generator_sobel)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    return results_val\n",
    "\n",
    "def model_func_branches(model_directory=None, custom_objects=None):\n",
    "    \"\"\" LOAD GENERATOR\"\"\"\n",
    "    #model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    results_train = model_func_branches_training_eval(model_directory, custom_objects)\n",
    "    results_val = model_func_branches_testing_eval(model_directory, custom_objects)\n",
    "\n",
    "    #test generator with sobel - X output is [original_image, processed_image]\n",
    "\n",
    "\n",
    "    \"\"\" END GENERATOR \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #with strategy.scope():\n",
    "    #del train_generator_sobel\n",
    "    print(\"Evaluating on Test Set\")\n",
    "    \n",
    "    \n",
    "    #del test_generator_sobel\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return results_train, results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_run(model_checkpoint_directory, model, custom_objects):\n",
    "    # run evaluation of models\n",
    "    temp_train_results, temp_val_results = model_func(model_checkpoint_directory+model,custom_objects=custom_objects)\n",
    "    \n",
    "    # create dataframe of particular model results\n",
    "    temp_train_results_df = pd.DataFrame(temp_train_results).T\n",
    "    temp_val_results_df = pd.DataFrame(temp_val_results).T\n",
    "    \n",
    "    # name the columns to match metrics\n",
    "    temp_train_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    temp_val_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    # name index to match model name\n",
    "    temp_train_results_df.index = [model]\n",
    "    temp_val_results_df.index = [model]\n",
    "\n",
    "    return temp_train_results_df, temp_val_results_df\n",
    "\n",
    "def model_evaluation_run_branches(model_checkpoint_directory, model, custom_objects):\n",
    "    # run evaluation of models\n",
    "    temp_train_results, temp_val_results = model_func_branches(model_checkpoint_directory+model,custom_objects=custom_objects)\n",
    "    \n",
    "    # create dataframe of particular model results\n",
    "    temp_train_results_df = pd.DataFrame(temp_train_results).T\n",
    "    temp_val_results_df = pd.DataFrame(temp_val_results).T\n",
    "    \n",
    "    # name the columns to match metrics\n",
    "    temp_train_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    temp_val_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    # name index to match model name\n",
    "    temp_train_results_df.index = [model]\n",
    "    temp_val_results_df.index = [model]\n",
    "\n",
    "    return temp_train_results_df, temp_val_results_df"
   ]
  },
  {
   "source": [
    "# Model Evaluation Start"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Unet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# testing structure\n",
    "result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "for model in model_list[14:]:\n",
    "    print(\"MODEL TO BE EVALUATED: \")\n",
    "    print(model)\n",
    "    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={'wbce': wbce})\n",
    "\n",
    "    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "    print(\"Current Training Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_train_df)\n",
    "    print(\"Current Validation Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_val_df)\n",
    "    print(\"...Evaluation Complete\")\n",
    "    result_train_df.to_csv('training_results_unet.csv')\n",
    "    result_val_df.to_csv('validation_results_unet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "# make a function to evaluate results for each epoch model with training and validation data in a particular directory \n",
    "# vizualize a couple outputs from the best model"
   ]
  },
  {
   "source": [
    "## Unet Single Branch\n",
    "y-model-1-unet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing structure\n",
    "#directory of models to iterate through\n",
    "model_checkpoint_directory = 'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model--unet/checkpoints/traintestrun/'\n",
    "model_list = os.listdir(model_checkpoint_directory)\n",
    "print(model_list\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "for model in model_list:\n",
    "    print(\"MODEL TO BE EVALUATED: \")\n",
    "    print(model)\n",
    "    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={'weighted_bincrossentropy': weighted_bincrossentropy})\n",
    "\n",
    "    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "    print(\"Current Training Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_train_df)\n",
    "    print(\"Current Validation Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_val_df)\n",
    "    print(\"...Evaluation Complete\")\n",
    "\n",
    "    result_train_df.to_csv('training_results_y_model_1_unet.csv')\n",
    "    result_val_df.to_csv('validation_results_unet_y_model_1_unet.csv')"
   ]
  },
  {
   "source": [
    "## y-model-2-unet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing structure\n",
    "#directory of models to iterate through\n",
    "model_checkpoint_directory = 'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model-2-unet/checkpoints/traintestrun/'\n",
    "model_list = os.listdir(model_checkpoint_directory)\n",
    "print(model_list)\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "for model in model_list:\n",
    "    print(\"MODEL TO BE EVALUATED: \")\n",
    "    print(model)\n",
    "    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={'weighted_bincrossentropy': weighted_bincrossentropy})\n",
    "\n",
    "    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "    print(\"Current Training Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_train_df)\n",
    "    print(\"Current Validation Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_val_df)\n",
    "    print(\"...Evaluation Complete\")\n",
    "\n",
    "    result_train_df.to_csv('training_results_y_model_2_unet.csv')\n",
    "    result_val_df.to_csv('validation_results_unet_y_model_2_unet.csv')"
   ]
  },
  {
   "source": [
    "## y-model-branches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['model.01-0.09-0.76.h5', 'model.01-0.09-0.77.h5', 'model.02-0.08-0.82.h5', 'model.03-0.08-0.82.h5', 'model.04-0.07-0.83.h5', 'model.05-0.07-0.83.h5', 'model.06-0.07-0.83.h5', 'model.07-0.07-0.83.h5', 'model.08-0.07-0.84.h5', 'model.09-0.07-0.84.h5', 'model.10-0.07-0.84.h5', 'model.11-0.07-0.84.h5', 'model.12-0.07-0.85.h5', 'model.13-0.07-0.85.h5', 'model.14-0.07-0.85.h5', 'model.15-0.07-0.85.h5', 'model.16-0.07-0.85.h5', 'model.17-0.07-0.85.h5', 'model.18-0.07-0.85.h5', 'model.19-0.06-0.85.h5', 'model.20-0.06-0.85.h5']\n",
      "MODEL TO BE EVALUATED: \n",
      "model.01-0.09-0.76.h5\n",
      "Number of images:  7813\n",
      "Number of processed:  7813\n",
      "Number of targets:  7813\n",
      "Evaluating on Training Set\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "3906/3906 [==============================] - 599s 152ms/step - loss: 0.0864 - accuracy: 0.7028 - mean_io_u: 0.4524 - recall: 0.8672 - precision: 0.2251\n",
      "Number of images:  1953\n",
      "Number of processed:  1953\n",
      "Number of targets:  1953\n",
      "976/976 [==============================] - 177s 179ms/step - loss: 0.0874 - accuracy: 0.6945 - mean_io_u: 0.4528 - recall: 0.8653 - precision: 0.2181\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-48993e6cee59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MODEL TO BE EVALUATED: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtemp_train_results_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_val_results_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluation_run_branches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'weighted_bincrossentropy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mweighted_bincrossentropy\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mresult_train_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_train_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_train_results_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-5094f376d740>\u001b[0m in \u001b[0;36mmodel_evaluation_run_branches\u001b[1;34m(model_checkpoint_directory, model, custom_objects)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_evaluation_run_branches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# run evaluation of models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mtemp_train_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_val_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_func_branches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_directory\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# create dataframe of particular model results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-805d843f2313>\u001b[0m in \u001b[0;36mmodel_func_branches\u001b[1;34m(model_directory, custom_objects)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m#with strategy.scope():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# testing structure\n",
    "#directory of models to iterate through\n",
    "model_checkpoint_directory = 'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model-branches/checkpoints/traintestrun/'\n",
    "model_list = os.listdir(model_checkpoint_directory)\n",
    "print(model_list)\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "    result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "    for model in model_list:\n",
    "        print(\"MODEL TO BE EVALUATED: \")\n",
    "        print(model)\n",
    "        temp_train_results_df, temp_val_results_df = model_evaluation_run_branches(model_checkpoint_directory, model, custom_objects={'weighted_bincrossentropy': weighted_bincrossentropy})\n",
    "\n",
    "        result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "        result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "        print(\"Current Training Results\")\n",
    "        print(\"------------\")\n",
    "        print(result_train_df)\n",
    "        print(\"Current Validation Results\")\n",
    "        print(\"------------\")\n",
    "        print(result_val_df)\n",
    "        print(\"...Evaluation Complete\")\n",
    "\n",
    "        result_train_df.to_csv('training_results_y_model_branches.csv')\n",
    "        result_val_df.to_csv('validation_results_unet_y_model_branches.csv')"
   ]
  }
 ]
}