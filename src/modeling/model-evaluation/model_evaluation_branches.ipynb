{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0f65f00ed884b0d74a6878126da3c63663535319d87509092f4fd534b10c59dc8",
   "display_name": "Python 3.8.8 64-bit ('asteroid_thesis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Evaluation \n",
    "This is the script to generate visuals and images of model results, since many of the models did not successfully train on validation sets.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.distribute import MirroredStrategy, HierarchicalCopyAllReduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.config.run_functions_eagerly(False)\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"]=\"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "strategy = MirroredStrategy(cross_device_ops=HierarchicalCopyAllReduce())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation generator\n",
    "from model_utils import artificial_lunar_landscapes, generate_image_paths\n",
    "from model_utils_sobel import artificial_lunar_landscapes as artificial_lunar_landscapes_sobel\n",
    "from model_utils_sobel import  generate_image_paths as generate_image_paths_sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "batch_size = 2\n",
    "image_size = (480,720,1)\n",
    "input_processed_size = (480,720,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ninput_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\\n)\\ntrain_generator = artificial_lunar_landscapes(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths\\n)\\n\\n\\n#test generator\\ninput_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\\n)\\ntest_generator = artificial_lunar_landscapes(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths\\n)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# ORIGNIAL TRAIN TEST GENERATOR (no Sobel)\n",
    "#training generator\n",
    "\"\"\"\n",
    "input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    ")\n",
    "train_generator = artificial_lunar_landscapes(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths\n",
    ")\n",
    "\n",
    "\n",
    "#test generator\n",
    "input_dir, target_dir, input_img_paths, target_img_paths = generate_image_paths(\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    ")\n",
    "test_generator = artificial_lunar_landscapes(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\ninput_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\\n    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\\n)\\ntrain_generator_sobel = artificial_lunar_landscapes_sobel(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    image_processed_size = input_processed_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths,\\n    input_img_processed_paths=process_img_paths\\n)\\n\\n#test generator with sobel - X output is [original_image, processed_image]\\ninput_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\\n    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\\n    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \\n    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\\n)\\ntest_generator_sobel = artificial_lunar_landscapes_sobel(\\n    batch_size=batch_size,\\n    image_size=image_size,\\n    image_processed_size = input_processed_size,\\n    input_img_paths=input_img_paths,\\n    target_img_paths=target_img_paths,\\n    input_img_processed_paths=process_img_paths\\n)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "### SOBEL GENERATOR\n",
    "# training generator with sobel - X output is [original_image, processed_image]\n",
    "\"\"\"\n",
    "input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    ")\n",
    "train_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    image_processed_size = input_processed_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths,\n",
    "    input_img_processed_paths=process_img_paths\n",
    ")\n",
    "\n",
    "#test generator with sobel - X output is [original_image, processed_image]\n",
    "input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "    processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\n",
    "    target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "    input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    ")\n",
    "test_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    image_processed_size = input_processed_size,\n",
    "    input_img_paths=input_img_paths,\n",
    "    target_img_paths=target_img_paths,\n",
    "    input_img_processed_paths=process_img_paths\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "def weighted_bincrossentropy(true, pred, weight_zero = 0.1, weight_one = 1):\n",
    "    \"\"\"\n",
    "    Calculates weighted binary cross entropy. The weights are fixed.\n",
    "        \n",
    "    This can be useful for unbalanced catagories.\n",
    "    \n",
    "    Adjust the weights here depending on what is required.\n",
    "    \n",
    "    For example if there are 10x as many positive classes as negative classes,\n",
    "        if you adjust weight_zero = 1.0, weight_one = 0.1, then false positives # predict rock but actually no rock\n",
    "        will be penalize 10 times as much as false negatives. # predict no rock but actually rock\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the binary cross entropy\n",
    "    bin_crossentropy = keras.backend.binary_crossentropy(true, pred)\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "\n",
    "    return keras.backend.mean(weighted_bin_crossentropy)\n",
    "\n",
    "def wbce( y_true, y_pred, weight1=1, weight0=0.1 ) :\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
    "    logloss = -(y_true * K.log(y_pred) * weight1 + (1 - y_true) * K.log(1 - y_pred) * weight0 )\n",
    "    return K.mean( logloss, axis=-1)"
   ]
  },
  {
   "source": [
    "### Functions\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model-0.h5',\n",
       " 'model-1.h5',\n",
       " 'model-2.h5',\n",
       " 'model-3.h5',\n",
       " 'model-4.h5',\n",
       " 'model-5.h5',\n",
       " 'model-6.h5',\n",
       " 'model-7.h5',\n",
       " 'model-8.h5',\n",
       " 'model-9.h5',\n",
       " 'model-10.h5',\n",
       " 'model-11.h5',\n",
       " 'model-12.h5',\n",
       " 'model-13.h5',\n",
       " 'model-14.h5',\n",
       " 'model-15.h5',\n",
       " 'model-16.h5',\n",
       " 'model-17.h5',\n",
       " 'model-18.h5',\n",
       " 'model-19.h5']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model_checkpoint_directory = '../results/simple-modeling/unet-weighted-bce-trainval/checkpoints/'\n",
    "os.listdir(model_checkpoint_directory)\n",
    "\n",
    "model_list = []\n",
    "for i in range(0,20):\n",
    "    model_list.append(f'model-{i}.h5')\n",
    "\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_func(model_directory=None, custom_objects=None):\n",
    "    # LOAD GENERATOR#\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    "    )\n",
    "    train_generator = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "\n",
    "    #test generator with sobel - X output is [original_image, processed_image]\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    "    )\n",
    "    test_generator = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "\n",
    "\n",
    "    #END GENERATOR #\n",
    "    \n",
    "    \n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    print(model.summary())\n",
    "    \n",
    "    #with strategy.scope():\n",
    "    print(\"Evaluating on Training Set\")\n",
    "    results_train = model.evaluate(train_generator)\n",
    "    \n",
    "    print(\"Evaluating on Test Set\")\n",
    "    results_val = model.evaluate(test_generator)\n",
    "    \n",
    "    del test_generator\n",
    "    del train_generator\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    \n",
    "    \n",
    "    return results_train, results_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_func_branches_training_eval(model_directory, custom_objects):\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/train/render-og'\n",
    "    )\n",
    "    train_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "    print(\"Evaluating on Training Set\")\n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    print(model.summary())\n",
    "    results_train = model.evaluate(train_generator_sobel)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    return results_train\n",
    "\n",
    "def model_func_branches_testing_eval(model_directory, custom_objects):\n",
    "    input_dir, target_dir, input_img_paths, target_img_paths, process_img_paths = generate_image_paths_sobel(\n",
    "        processed_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-processed',\n",
    "        target_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/mask-og', \n",
    "        input_dir='D:/TJPersonalCloud/Programming/msds-thesis-data/data-ml/split-data/test/render-og'\n",
    "    )\n",
    "    test_generator_sobel = artificial_lunar_landscapes_sobel(\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        image_processed_size = input_processed_size,\n",
    "        input_img_paths=input_img_paths,\n",
    "        target_img_paths=target_img_paths,\n",
    "        input_img_processed_paths=process_img_paths\n",
    "    )\n",
    "    model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    results_val = model.evaluate(test_generator_sobel)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    return results_val\n",
    "\n",
    "def model_func_branches(model_directory=None, custom_objects=None):\n",
    "    \"\"\" LOAD GENERATOR\"\"\"\n",
    "    #model = load_model(model_directory, custom_objects=custom_objects)\n",
    "    results_train = model_func_branches_training_eval(model_directory, custom_objects)\n",
    "    results_val = model_func_branches_testing_eval(model_directory, custom_objects)\n",
    "\n",
    "    #test generator with sobel - X output is [original_image, processed_image]\n",
    "\n",
    "\n",
    "    \"\"\" END GENERATOR \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #with strategy.scope():\n",
    "    #del train_generator_sobel\n",
    "    print(\"Evaluating on Test Set\")\n",
    "    \n",
    "    \n",
    "    #del test_generator_sobel\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return results_train, results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_run(model_checkpoint_directory, model, custom_objects):\n",
    "    # run evaluation of models\n",
    "    temp_train_results, temp_val_results = model_func(model_checkpoint_directory+model,custom_objects=custom_objects)\n",
    "    \n",
    "    # create dataframe of particular model results\n",
    "    temp_train_results_df = pd.DataFrame(temp_train_results).T\n",
    "    temp_val_results_df = pd.DataFrame(temp_val_results).T\n",
    "    \n",
    "    # name the columns to match metrics\n",
    "    temp_train_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    temp_val_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    # name index to match model name\n",
    "    temp_train_results_df.index = [model]\n",
    "    temp_val_results_df.index = [model]\n",
    "\n",
    "    return temp_train_results_df, temp_val_results_df\n",
    "\n",
    "def model_evaluation_run_branches(model_checkpoint_directory, model, custom_objects):\n",
    "    # run evaluation of models\n",
    "    temp_train_results, temp_val_results = model_func_branches(model_checkpoint_directory+model,custom_objects=custom_objects)\n",
    "    \n",
    "    # create dataframe of particular model results\n",
    "    temp_train_results_df = pd.DataFrame(temp_train_results).T\n",
    "    temp_val_results_df = pd.DataFrame(temp_val_results).T\n",
    "    \n",
    "    # name the columns to match metrics\n",
    "    temp_train_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    temp_val_results_df.columns = ['loss','accuracy','mean_iou','recall','precision']\n",
    "    # name index to match model name\n",
    "    temp_train_results_df.index = [model]\n",
    "    temp_val_results_df.index = [model]\n",
    "\n",
    "    return temp_train_results_df, temp_val_results_df"
   ]
  },
  {
   "source": [
    "# Model Evaluation Start"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.backend import set_session, clear_session, get_session\n",
    "from tensorflow.compat.v1 import ConfigProto, Session\n",
    "#import tensorflow\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "reset_keras()"
   ]
  },
  {
   "source": [
    "## y-model-branches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# testing structure\\n#directory of models to iterate through\\nmodel_checkpoint_directory = \\'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model-branches/checkpoints/traintestrun/\\'\\nmodel_list = os.listdir(model_checkpoint_directory)\\nprint(model_list)\\n\\n#with strategy.scope():\\n\\nresult_train_df = pd.DataFrame(columns=[\\'loss\\',\\'accuracy\\',\\'mean_iou\\',\\'recall\\',\\'precision\\'])\\nresult_val_df = pd.DataFrame(columns=[\\'loss\\',\\'accuracy\\',\\'mean_iou\\',\\'recall\\',\\'precision\\'])\\nfor model in model_list:\\n    print(\"MODEL TO BE EVALUATED: \")\\n    print(model)\\n    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={\\'weighted_bincrossentropy\\': weighted_bincrossentropy})\\n\\n    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\\n    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\\n\\n    print(\"Current Training Results\")\\n    print(\"------------\")\\n    print(result_train_df)\\n    print(\"Current Validation Results\")\\n    print(\"------------\")\\n    print(result_val_df)\\n    print(\"...Evaluation Complete\")\\n\\n    result_train_df.to_csv(\\'training_results_y_model_branches.csv\\')\\n    result_val_df.to_csv(\\'validation_results_unet_y_model_branches.csv\\')\\n\\n    K.clear_session()\\n    gc.collect()\\n    keras.backend.clear_session()\\n    for i in range(3): gc.collect()\\n    reset_keras()\\n    '"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\"\"\"\n",
    "# testing structure\n",
    "#directory of models to iterate through\n",
    "model_checkpoint_directory = 'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model-branches/checkpoints/traintestrun/'\n",
    "model_list = os.listdir(model_checkpoint_directory)\n",
    "print(model_list)\n",
    "\n",
    "#with strategy.scope():\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "for model in model_list:\n",
    "    print(\"MODEL TO BE EVALUATED: \")\n",
    "    print(model)\n",
    "    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={'weighted_bincrossentropy': weighted_bincrossentropy})\n",
    "\n",
    "    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "    print(\"Current Training Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_train_df)\n",
    "    print(\"Current Validation Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_val_df)\n",
    "    print(\"...Evaluation Complete\")\n",
    "\n",
    "    result_train_df.to_csv('training_results_y_model_branches.csv')\n",
    "    result_val_df.to_csv('validation_results_unet_y_model_branches.csv')\n",
    "\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    reset_keras()\n",
    "    \"\"\""
   ]
  },
  {
   "source": [
    "### y model branches filtersample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['model.01-0.09-0.73.h5', 'model.02-0.07-0.82.h5', 'model.03-0.07-0.85.h5', 'model.04-0.06-0.85.h5', 'model.05-0.06-0.85.h5', 'model.06-0.06-0.86.h5', 'model.07-0.06-0.87.h5', 'model.08-0.06-0.87.h5', 'model.09-0.06-0.88.h5', 'model.10.h5', 'model.11.h5', 'model.12.h5', 'model.13.h5', 'model.14.h5', 'model.15.h5', 'model.16.h5', 'model.17.h5', 'model.18.h5', 'model.19.h5', 'model.20.h5']\n",
      "MODEL TO BE EVALUATED: \n",
      "model.18.h5\n",
      "Number of images:  7813\n",
      "Number of processed:  7813\n",
      "Number of targets:  7813\n",
      "Number of images:  1953\n",
      "Number of processed:  1953\n",
      "Number of targets:  1953\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 480, 720, 64) 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 480, 720, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 240, 360, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 240, 360, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 120, 180, 512 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 120, 180, 128 589952      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 240, 360, 128 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 240, 360, 64) 73792       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 480, 720, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 480, 720, 32) 18464       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 480, 720, 15) 4335        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 480, 720, 1)  16          conv2d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,425,887\n",
      "Trainable params: 1,425,887\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Evaluating on Training Set\n",
      "3906/3906 [==============================] - 713s 181ms/step - loss: 0.0514 - accuracy: 0.8977 - mean_io_u: 0.4524 - recall: 0.8666 - precision: 0.4797\n",
      "Evaluating on Test Set\n",
      "976/976 [==============================] - 196s 200ms/step - loss: 0.0527 - accuracy: 0.8931 - mean_io_u: 0.4528 - recall: 0.8609 - precision: 0.4641\n",
      "Current Training Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.051367  0.897727  0.452355  0.866606    0.47972\n",
      "Current Validation Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.052731   0.89306  0.452811  0.860939   0.464128\n",
      "...Evaluation Complete\n",
      "140\n",
      "MODEL TO BE EVALUATED: \n",
      "model.19.h5\n",
      "Number of images:  7813\n",
      "Number of processed:  7813\n",
      "Number of targets:  7813\n",
      "Number of images:  1953\n",
      "Number of processed:  1953\n",
      "Number of targets:  1953\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 480, 720, 64) 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 480, 720, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 240, 360, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 240, 360, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 120, 180, 512 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 120, 180, 128 589952      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 240, 360, 128 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 240, 360, 64) 73792       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 480, 720, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 480, 720, 32) 18464       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 480, 720, 15) 4335        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 480, 720, 1)  16          conv2d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,425,887\n",
      "Trainable params: 1,425,887\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Evaluating on Training Set\n",
      "3906/3906 [==============================] - 1013s 259ms/step - loss: 0.0516 - accuracy: 0.9076 - mean_io_u: 0.4524 - recall: 0.8543 - precision: 0.5091\n",
      "Evaluating on Test Set\n",
      "976/976 [==============================] - 235s 241ms/step - loss: 0.0529 - accuracy: 0.9056 - mean_io_u: 0.4528 - recall: 0.8522 - precision: 0.5000\n",
      "Current Training Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.051367  0.897727  0.452355  0.866606   0.479720\n",
      "1  0.051644  0.907613  0.452355  0.854340   0.509083\n",
      "Current Validation Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.052731   0.89306  0.452811  0.860939   0.464128\n",
      "1  0.052858   0.90561  0.452810  0.852223   0.499968\n",
      "...Evaluation Complete\n",
      "140\n",
      "MODEL TO BE EVALUATED: \n",
      "model.20.h5\n",
      "Number of images:  7813\n",
      "Number of processed:  7813\n",
      "Number of targets:  7813\n",
      "Number of images:  1953\n",
      "Number of processed:  1953\n",
      "Number of targets:  1953\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 480, 720, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 480, 720, 64) 640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 480, 720, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 240, 360, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 240, 360, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 360, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 120, 180, 128 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 180, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 120, 180, 512 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 120, 180, 128 589952      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 240, 360, 128 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 240, 360, 64) 73792       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 480, 720, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 480, 720, 32) 18464       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 480, 720, 15) 4335        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 480, 720, 1)  16          conv2d_9[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,425,887\n",
      "Trainable params: 1,425,887\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Evaluating on Training Set\n",
      "3906/3906 [==============================] - 858s 219ms/step - loss: 0.0515 - accuracy: 0.8893 - mean_io_u: 0.4524 - recall: 0.8806 - precision: 0.4580\n",
      "Evaluating on Test Set\n",
      "976/976 [==============================] - 221s 226ms/step - loss: 0.0529 - accuracy: 0.8843 - mean_io_u: 0.4528 - recall: 0.8752 - precision: 0.4428\n",
      "Current Training Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.051367  0.897727  0.452355  0.866606   0.479720\n",
      "1  0.051644  0.907613  0.452355  0.854340   0.509083\n",
      "2  0.051476  0.889333  0.452355  0.880625   0.458035\n",
      "Current Validation Results\n",
      "------------\n",
      "       loss  accuracy  mean_iou    recall  precision\n",
      "0  0.052731  0.893060  0.452811  0.860939   0.464128\n",
      "1  0.052858  0.905610  0.452810  0.852223   0.499968\n",
      "2  0.052886  0.884268  0.452810  0.875248   0.442774\n",
      "...Evaluation Complete\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "# testing structure\n",
    "#directory of models to iterate through\n",
    "model_checkpoint_directory = 'D:/ProgrammingD/github/thesis/modeling/results/custom-modeling/y-model-branches-filtersample/checkpoints/traintestrun/'\n",
    "model_list = sorted(os.listdir(model_checkpoint_directory))\n",
    "print(model_list)\n",
    "\n",
    "#with strategy.scope():\n",
    "\n",
    "result_train_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "result_val_df = pd.DataFrame(columns=['loss','accuracy','mean_iou','recall','precision'])\n",
    "for model in model_list[17:]:\n",
    "    print(\"MODEL TO BE EVALUATED: \")\n",
    "    print(model)\n",
    "    temp_train_results_df, temp_val_results_df = model_evaluation_run(model_checkpoint_directory, model, custom_objects={'weighted_bincrossentropy': weighted_bincrossentropy})\n",
    "\n",
    "    result_train_df = result_train_df.append(temp_train_results_df,ignore_index=True)\n",
    "    result_val_df = result_val_df.append(temp_val_results_df, ignore_index=True)\n",
    "\n",
    "    print(\"Current Training Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_train_df)\n",
    "    print(\"Current Validation Results\")\n",
    "    print(\"------------\")\n",
    "    print(result_val_df)\n",
    "    print(\"...Evaluation Complete\")\n",
    "\n",
    "    result_train_df.to_csv('training_results_y_model_branches_filtersample.csv')\n",
    "    result_val_df.to_csv('validation_results_unet_y_model_branches_filtersample.csv')\n",
    "\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    keras.backend.clear_session()\n",
    "    for i in range(3): gc.collect()\n",
    "    reset_keras()"
   ]
  }
 ]
}